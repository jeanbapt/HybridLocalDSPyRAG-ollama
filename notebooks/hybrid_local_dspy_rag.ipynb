{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55c7a1e",
   "metadata": {},
   "source": [
    "# Hybrid Local DSPy RAG with Ollama\n",
    "\n",
    "This notebook implements a French RAG (Retrieval-Augmented Generation) system using:\n",
    "- Hybrid retrieval (CamemBERT + BM25)\n",
    "- DSPy for orchestration\n",
    "- Mistral via Ollama for language generation\n",
    "- Metal (MPS) acceleration for Mac\n",
    "- MLX for optimized computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ac3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install required libraries\n",
    "!pip install mlx mlx-torch\n",
    "!pip install transformers rank_bm25 nltk torch dspy-ai --quiet\n",
    "!pip install sentencepiece==0.1.99\n",
    "!pip install ollama\n",
    "!pip install --upgrade dspy-ai\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load CamemBERT and tokenizer\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import torch\n",
    "\n",
    "# Check for Metal support\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert/camembert-base\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0bc577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sample French documents\n",
    "documents = [\n",
    "    # Climate and Environment\n",
    "    \"Le changement climatique menace la biodiversité mondiale et accélère l'extinction des espèces.\",\n",
    "    \"Les océans jouent un rôle crucial dans la régulation du climat et l'absorption du CO2.\",\n",
    "    \"La fonte des glaciers arctiques modifie les courants océaniques et affecte le climat global.\",\n",
    "    \"Les forêts tropicales sont essentielles pour maintenir l'équilibre climatique de la planète.\",\n",
    "    \n",
    "    # Renewable Energy\n",
    "    \"Les énergies renouvelables sont essentielles pour lutter contre le réchauffement climatique.\",\n",
    "    \"L'énergie solaire devient de plus en plus accessible et efficace pour les particuliers.\",\n",
    "    \"Les éoliennes offshore représentent une source importante d'énergie propre en Europe.\",\n",
    "    \"La transition énergétique nécessite des investissements massifs en infrastructure.\",\n",
    "    \n",
    "    # Technology and AI\n",
    "    \"L'intelligence artificielle transforme radicalement les méthodes de travail traditionnelles.\",\n",
    "    \"Le machine learning révolutionne la recherche médicale et le diagnostic des maladies.\",\n",
    "    \"Les algorithmes de deep learning permettent une meilleure compréhension du langage naturel.\",\n",
    "    \"La robotique collaborative améliore la sécurité et l'efficacité dans l'industrie.\",\n",
    "    \n",
    "    # French Culture\n",
    "    \"La gastronomie française est inscrite au patrimoine mondial de l'UNESCO.\",\n",
    "    \"Le cinéma français est reconnu pour sa créativité et sa diversité artistique.\",\n",
    "    \"Les traditions viticoles françaises se transmettent de génération en génération.\",\n",
    "    \"Le patrimoine architectural français témoigne de siècles d'histoire et d'innovation.\",\n",
    "    \n",
    "    # Science and Research\n",
    "    \"Les chercheurs français développent de nouveaux traitements contre le cancer.\",\n",
    "    \"Les découvertes en physique quantique ouvrent de nouvelles perspectives technologiques.\",\n",
    "    \"La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\",\n",
    "    \"Les études sur le génome humain révèlent de nouveaux mécanismes biologiques.\",\n",
    "    \n",
    "    # Biodiversity\n",
    "    \"La protection des abeilles est cruciale pour la préservation de la biodiversité.\",\n",
    "    \"Les récifs coralliens abritent 25% de la vie marine mondiale.\",\n",
    "    \"La déforestation menace des milliers d'espèces animales et végétales.\",\n",
    "    \"Les zones humides sont des écosystèmes essentiels pour la biodiversité.\",\n",
    "    \n",
    "    # Sustainable Development\n",
    "    \"L'agriculture biologique contribue à la préservation des sols et de la biodiversité.\",\n",
    "    \"L'économie circulaire propose un modèle plus durable de consommation.\",\n",
    "    \"Les villes intelligentes optimisent leur consommation d'énergie et réduisent leur impact environnemental.\",\n",
    "    \"Le développement durable concilie progrès économique et protection de l'environnement.\",\n",
    "    \n",
    "    # Education and Innovation\n",
    "    \"L'éducation numérique transforme les méthodes d'apprentissage traditionnelles.\",\n",
    "    \"Les fab labs encouragent l'innovation et la créativité technologique.\",\n",
    "    \"La formation continue devient essentielle dans un monde en constante évolution.\",\n",
    "    \"Les nouvelles technologies facilitent l'accès à l'éducation pour tous.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16814e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# 4. ColBERT-style encoder\n",
    "def encode(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze(0), inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "# Encode all documents\n",
    "colbert_index = [(doc, *encode(doc)) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db7abe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. BM25 Retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a3d7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Hybrid Retriever\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def colbert_score(query, k=3):\n",
    "    q_embed, q_mask = encode(query)\n",
    "    scores = []\n",
    "    for doc, d_embed, d_mask in colbert_index:\n",
    "        sim = torch.einsum('id,jd->ij', q_embed, d_embed)\n",
    "        maxsim = sim.max(dim=1).values\n",
    "        score = maxsim.mean().item()\n",
    "        scores.append((doc, score))\n",
    "    return sorted(scores, key=lambda x: -x[1])[:k]\n",
    "\n",
    "def bm25_score(query, k=3):\n",
    "    tokenized_query = word_tokenize(query.lower())\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    ranked = sorted(enumerate(scores), key=lambda x: -x[1])[:k]\n",
    "    return [(documents[i], scores[i]) for i, _ in ranked]\n",
    "\n",
    "def hybrid_score(query, alpha=0.5, k=3):\n",
    "    colbert_results = dict(colbert_score(query, k=10))\n",
    "    bm25_results = dict(bm25_score(query, k=10))\n",
    "    combined = {}\n",
    "    for doc in set(colbert_results) | set(bm25_results):\n",
    "        c = colbert_results.get(doc, 0)\n",
    "        b = bm25_results.get(doc, 0)\n",
    "        combined[doc] = alpha * c + (1 - alpha) * b\n",
    "    return sorted(combined.items(), key=lambda x: -x[1])[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f96ca061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.7039 - Les océans jouent un rôle crucial dans la régulation du climat et l'absorption du CO2.\n",
      "17.4164 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "16.2568 - Les forêts tropicales sont essentielles pour maintenir l'équilibre climatique de la planète.\n"
     ]
    }
   ],
   "source": [
    "# 7. Try a French query\n",
    "query = \"Quel est l'impact du climat sur la nature ?\"\n",
    "for doc, score in hybrid_score(query, alpha=0.8):\n",
    "    print(f\"{score:.4f} - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e03ed",
   "metadata": {},
   "source": [
    "# 8. DSPy Integration with Mistral via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4592b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Mistral (Ollama) as DSPy LM\n",
    "import dspy\n",
    "import ollama\n",
    "import time\n",
    "\n",
    "class MistralOllamaLM(dspy.LM):\n",
    "    def __init__(self, max_retries=3, timeout=30):\n",
    "        super().__init__(model='mistral')\n",
    "        self.max_retries = max_retries\n",
    "        self.timeout = timeout\n",
    "        self.client = ollama.Client()\n",
    "\n",
    "    def __call__(self, prompt, **kwargs):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = self.client.chat(\n",
    "                    model='mistral',\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    options={\"timeout\": self.timeout * 1000}\n",
    "                )\n",
    "                return response['message']['content']\n",
    "            except Exception as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    raise Exception(f\"Failed to get response from Ollama after {self.max_retries} attempts: {str(e)}\")\n",
    "                print(f\"Attempt {attempt + 1} failed, retrying...\")\n",
    "                time.sleep(1)\n",
    "\n",
    "lm = MistralOllamaLM()\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df529404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy Retriever wrapper using hybrid_score\n",
    "from dspy.retrieve import Retrieve\n",
    "\n",
    "class HybridDSPyRetriever(Retrieve):\n",
    "    def __init__(self, alpha=0.8, k=3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "\n",
    "    def retrieve(self, query, k=None):\n",
    "        results = hybrid_score(query, alpha=self.alpha, k=k or self.k)\n",
    "        return [dspy.Passage(text=doc, score=score) for doc, score in results]\n",
    "\n",
    "retriever = HybridDSPyRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59a32ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hybrid retrieval (alpha=0.7):\n",
      "\n",
      "\n",
      "Question: Quel est l'impact du changement climatique sur les océans ?\n",
      "Résultats:\n",
      "15.9521 - Les océans jouent un rôle crucial dans la régulation du climat et l'absorption du CO2.\n",
      "14.3561 - Les forêts tropicales sont essentielles pour maintenir l'équilibre climatique de la planète.\n",
      "13.6654 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: Comment l'intelligence artificielle transforme-t-elle la médecine ?\n",
      "Résultats:\n",
      "13.2960 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "11.8425 - Les villes intelligentes optimisent leur consommation d'énergie et réduisent leur impact environnemental.\n",
      "11.7537 - La gastronomie française est inscrite au patrimoine mondial de l'UNESCO.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: Quelles sont les traditions culturelles importantes en France ?\n",
      "Résultats:\n",
      "24.1678 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "21.3804 - Les zones humides sont des écosystèmes essentiels pour la biodiversité.\n",
      "20.6250 - La formation continue devient essentielle dans un monde en constante évolution.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: Comment protéger la biodiversité et les écosystèmes ?\n",
      "Résultats:\n",
      "20.9333 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "20.8061 - Les zones humides sont des écosystèmes essentiels pour la biodiversité.\n",
      "18.3020 - Les océans jouent un rôle crucial dans la régulation du climat et l'absorption du CO2.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Question: Quel est le rôle des énergies renouvelables dans la transition énergétique ?\n",
      "Résultats:\n",
      "17.4511 - La recherche en biotechnologie permet des avancées majeures en médecine personnalisée.\n",
      "17.3493 - Les énergies renouvelables sont essentielles pour lutter contre le réchauffement climatique.\n",
      "15.8284 - La formation continue devient essentielle dans un monde en constante évolution.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DSPy Pipeline Implementation\n",
    "from dspy import Module, InputField, OutputField, Signature, Example\n",
    "\n",
    "class HybridRetriever(Module):\n",
    "    def __init__(self, hybrid_score_function, alpha=0.6, k=3):\n",
    "        super().__init__()\n",
    "        self.hybrid_score_function = hybrid_score_function\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, query):\n",
    "        results = self.hybrid_score_function(query, alpha=self.alpha, k=self.k)\n",
    "        return results\n",
    "\n",
    "class FrenchQAPipeline(Module):\n",
    "    def __init__(self, retriever):\n",
    "        super().__init__()\n",
    "        self.retriever = retriever\n",
    "        \n",
    "    def forward(self, question):\n",
    "        # Retrieve relevant passages\n",
    "        passages = self.retriever(question)\n",
    "        \n",
    "        # Format context from passages\n",
    "        context = \"\\n\".join([doc for doc, _ in passages])\n",
    "        \n",
    "        # Create prompt for Mistral\n",
    "        prompt = f\"\"\"Contexte:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Réponse:\"\"\"\n",
    "        \n",
    "        # Get answer from Mistral\n",
    "        response = lm(prompt)\n",
    "        return response\n",
    "\n",
    "# Initialize the pipeline\n",
    "retriever = HybridRetriever(hybrid_score_function=hybrid_score)\n",
    "qa_pipeline = FrenchQAPipeline(retriever)\n",
    "\n",
    "# Test queries with different focuses\n",
    "test_queries = [\n",
    "    \"Quel est l'impact du changement climatique sur les océans ?\",\n",
    "    \"Comment l'intelligence artificielle transforme-t-elle la médecine ?\",\n",
    "    \"Quelles sont les traditions culturelles importantes en France ?\",\n",
    "    \"Comment protéger la biodiversité et les écosystèmes ?\",\n",
    "    \"Quel est le rôle des énergies renouvelables dans la transition énergétique ?\",\n",
    "]\n",
    "\n",
    "print(\"Testing hybrid retrieval (alpha=0.7):\\n\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuestion: {query}\")\n",
    "    print(\"Résultats:\")\n",
    "    for doc, score in hybrid_score(query, alpha=0.7, k=3):\n",
    "        print(f\"{score:.4f} - {doc}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
